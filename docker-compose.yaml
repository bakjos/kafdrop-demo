version: "3"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    depends_on: [zookeeper]
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
  schema-registry:
    image: confluentinc/cp-schema-registry:6.2.0
    depends_on: [kafka]
    ports:
      - 8081:8081
    environment: 
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry

  kafka-connect:
    # image: commuredev.azurecr.io/confluentinc/kafka-connect-helm:latest
    image: kafka-connect-pg-es
    build: 
      context: .
      dockerfile: Dockerfile
    depends_on: [kafka,schema-registry]
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_AUTO_CREATE_TOPICS_ENABLE: "true"
      CONNECT_GROUP_ID: "kafka-connect-consumer"
      CONNECT_REST_ADVERTISED_HOST_NAME: "0.0.0.0"
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_PLUGIN_PATH: "/usr/share/confluent-hub-components"
      CONNECT_CONFIG_STORAGE_TOPIC: "confluent.connectors-configs" 
      CONNECT_OFFSET_STORAGE_TOPIC: "confluent.connectors-offsets" 
      CONNECT_STATUS_STORAGE_TOPIC: "confluent.connectors-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
  kafdrop:
    image: obsidiandynamics/kafdrop:3.27.0
    depends_on: [schema-registry]
    ports:
      - 9000:9000
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      CMD_ARGS: "--message.format=AVRO --schemaregistry.connect=http://schema-registry:8081"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
  
  akhq:
    # build:
    #   context: .
    image: tchiotludo/akhq
    depends_on: [kafka-connect]
    ports:
      - 8088:8080
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka:29092"
              schema-registry:
                url: "http://schema-registry:8081"
              connect:
                - name: "kafka-connect"
                  url: "http://kafka-connect:8083"

  postgresql:
    image: postgres:13.2
    environment:
      - POSTGRES_USER=root
      - POSTGRES_PASSWORD=
      - POSTGRES_HOST_AUTH_METHOD=trust
    command: postgres -c 'max_connections=250' -c 'wal_level=logical'
    ports:
      - 5432:5432
    ulimits:
      memlock:
        soft: -1
        hard: -1
  
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
    ports:
      - 9200:9200
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
